{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23294fcd-1c07-4540-9173-4deb69cf571f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching examples at: '/root/yolov10-main/gradio_cached_examples/31'\n",
      "Caching example 1/2\n",
      "\n",
      "0: 640x480 4 persons, 1 bus, 1 stop sign, 1220.6ms\n",
      "Speed: 12.5ms preprocess, 1220.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mruns/detect/predict21\u001b[0m\n",
      "Caching example 2/2\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 902.3ms\n",
      "Speed: 62.5ms preprocess, 902.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict22\u001b[0m\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ackownledgement: https://huggingface.co/spaces/kadirnar/Yolov10/blob/main/app.py\n",
    "# Thanks to @kadirnar\n",
    "\n",
    "import gradio as gr\n",
    "from ultralytics import YOLOv10\n",
    "\n",
    "\n",
    "def yolov10_inference(image, model_path, image_size, conf_threshold):\n",
    "    model = YOLOv10(model_path)\n",
    "\n",
    "    model.predict(source=image, imgsz=image_size,\n",
    "                  conf=conf_threshold, save=True)\n",
    "\n",
    "    return model.predictor.plotted_img[:, :, ::-1]\n",
    "\n",
    "\n",
    "def app():\n",
    "    with gr.Blocks():\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                image = gr.Image(type=\"pil\", label=\"Image\")\n",
    "\n",
    "                model_id = gr.Dropdown(\n",
    "                    label=\"Model\",\n",
    "                    choices=[\n",
    "                        \"yolov10n.pt\",\n",
    "                        \"yolov10s.pt\",\n",
    "                        \"yolov10m.pt\",\n",
    "                        \"yolov10b.pt\",\n",
    "                        \"yolov10l.pt\",\n",
    "                        \"yolov10x.pt\",\n",
    "                        \"best.pt\"\n",
    "                    ],\n",
    "                    value=\"best.pt\",\n",
    "                )\n",
    "                image_size = gr.Slider(\n",
    "                    label=\"Image Size\",\n",
    "                    minimum=320,\n",
    "                    maximum=1280,\n",
    "                    step=32,\n",
    "                    value=640,\n",
    "                )\n",
    "                conf_threshold = gr.Slider(\n",
    "                    label=\"Confidence Threshold\",\n",
    "                    minimum=0.0,\n",
    "                    maximum=1.0,\n",
    "                    step=0.1,\n",
    "                    value=0.25,\n",
    "                )\n",
    "                yolov10_infer = gr.Button(value=\"Detect Objects\")\n",
    "\n",
    "            with gr.Column():\n",
    "                output_image = gr.Image(type=\"numpy\", label=\"Annotated Image\")\n",
    "\n",
    "        yolov10_infer.click(\n",
    "            fn=yolov10_inference,\n",
    "            inputs=[\n",
    "                image,\n",
    "                model_id,\n",
    "                image_size,\n",
    "                conf_threshold,\n",
    "            ],\n",
    "            outputs=[output_image],\n",
    "        )\n",
    "\n",
    "        gr.Examples(\n",
    "            examples=[\n",
    "                [\n",
    "                    \"ultralytics/assets/bus.jpg\",\n",
    "                    \"yolov10s.pt\",\n",
    "                    640,\n",
    "                    0.25,\n",
    "                ],\n",
    "                [\n",
    "                    \"ultralytics/assets/zidane.jpg\",\n",
    "                    \"yolov10s.pt\",\n",
    "                    640,\n",
    "                    0.25,\n",
    "                ],\n",
    "            ],\n",
    "            fn=yolov10_inference,\n",
    "            inputs=[\n",
    "                image,\n",
    "                model_id,\n",
    "                image_size,\n",
    "                conf_threshold,\n",
    "            ],\n",
    "            outputs=[output_image],\n",
    "            cache_examples=True,\n",
    "        )\n",
    "\n",
    "\n",
    "gradio_app = gr.Blocks()\n",
    "with gradio_app:\n",
    "    gr.HTML(\n",
    "        \"\"\"\n",
    "    <h1 style='text-align: center'>\n",
    "    YOLOv10: Real-Time End-to-End Object Detection\n",
    "    </h1>\n",
    "    \"\"\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            app()\n",
    "\n",
    "gradio_app.launch(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378fe643-9644-4756-8970-6e066ec25be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
